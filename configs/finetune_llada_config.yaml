# sample config file for finetuning llada model
learning_rate: 2e-5
temperature: 0.0
alpha: 0.5
dataset: "allenai/c4"
batch_size: 4
accum_steps: 16
remask_ratio: 0.5
mask_ratio: 0.25
max_steps: 50000